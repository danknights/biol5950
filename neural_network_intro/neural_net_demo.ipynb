{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4231518b-5f06-4160-aece-dabaad6b70a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Simple version with for loop for deep NNs\n",
    "import numpy as np\n",
    "\n",
    "def nn(inputs, weights, biases):\n",
    "    \"\"\"inputs is a 1 x m matrix of input values\n",
    "       weights is a list of length n, each element is an m x p matrix\n",
    "           of weights for a layer (incl. output layer)\n",
    "       biases is a p x n matrix of biases (incl. output)\n",
    "           so each column is the biases for one layer\n",
    "    \"\"\"\n",
    "    # Calculate values for each layer\n",
    "    for i in range(len(weights)):\n",
    "        inputs = np.dot(inputs, weights[i]) + biases[:,i] # mat mult and bias\n",
    "        inputs[inputs < 0] = 0\n",
    "    return inputs\n",
    "\n",
    "# Define the weights and biases\n",
    "# This network will output a positive value if input1 >> input2,\n",
    "# and vice versa.\n",
    "# The biases determine the definition of \">>\" and \"<<\"\n",
    "hidden_weights = np.array([[1, -1],[-1, 1]])\n",
    "output_weights = np.array([[1, 0],[0, 1]])\n",
    "biases = np.array([[-1, 0], [-1, 0]])\n",
    "weights = [hidden_weights, output_weights]\n",
    "\n",
    "# Set example inputs\n",
    "inputs = np.array([10,3])\n",
    "nn(inputs, weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ac6a677-31bf-4119-8c11-09b64f9c6f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can we make a nn for \"o\" responding to \"x\" move in tic tac toe?\n",
    "# The inputs and outputs 1-9 are the cells ordered by row\n",
    "# Strategy: If \"x\" goes in the center, go in a corner; if\n",
    "# \"x\" goes anywhere else, go in the center.\n",
    "\n",
    "inputs = np.array([0,0,0,0,0,1,0,0,0]).T # 3x3 board by rows\n",
    "weights = [np.array([[1,0,0,0,0,0,0,0,0],[1,0,0,0,0,0,0,0,0],[1,0,0,0,0,0,0,0,0],[1,0,0,0,0,0,0,0,0],[0,0,0,0,1,0,0,0,0],[1,0,0,0,0,0,0,0,0],[1,0,0,0,0,0,0,0,0],[1,0,0,0,0,0,0,0,0],[1,0,0,0,0,0,0,0,0]])]\n",
    "biases = np.array([[0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0]]).T\n",
    "\n",
    "nn(inputs, weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb33001b-3f55-47b6-93df-1f7b060c3957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Layer 0.\n",
      "Inputs: \n",
      "[10  3]\n",
      "Inputs * weights + bias:\n",
      "[ 6 -8]\n",
      "After ReLU activation:\n",
      "[6 0]\n",
      "\n",
      "Layer 1.\n",
      "Inputs: \n",
      "[6 0]\n",
      "Inputs * weights + bias:\n",
      "[6 0]\n",
      "After ReLU activation:\n",
      "[6 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([6, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the same version but with print statements\n",
    "import numpy as np\n",
    "\n",
    "def nn(inputs, weights, biases):\n",
    "    \"\"\"inputs is a 1 x m matrix of input values\n",
    "       weights is a list of length n, each element is an m x p matrix\n",
    "           of weights for a layer (incl. output layer)\n",
    "       biases is a p x n matrix of biases (incl. output)\n",
    "           so each column is the biases for one layer\n",
    "\n",
    "       currently only works for 1 hidden layer\n",
    "    \"\"\"\n",
    "    # Calculate values for each layer\n",
    "    for i in range(len(weights)):\n",
    "        print(\"\")\n",
    "        print(f'Layer {i}.')\n",
    "        print('Inputs: ')\n",
    "        print(inputs)\n",
    "        \n",
    "        inputs = np.dot(inputs, weights[i]) + biases[:,i] # mat mult and bias\n",
    "        print('Inputs * weights + bias:')\n",
    "        print(inputs)\n",
    "        \n",
    "        inputs[inputs < 0] = 0\n",
    "        print('After ReLU activation:')\n",
    "        print(inputs)\n",
    "\n",
    "    return inputs\n",
    "    \n",
    "inputs = np.array([10,3])\n",
    "hidden_weights = np.array([[1, -1],[-1, 1]])\n",
    "output_weights = np.array([[1, 0],[0, 1]])\n",
    "biases = np.array([[-1, 0], [-1, 0]])\n",
    "weights = [hidden_weights, output_weights]\n",
    "nn(inputs, weights, biases)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
