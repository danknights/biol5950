{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02911bdb-0349-4b12-b094-04397b809666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input values:\n",
      "[10  3]\n",
      "Hidden layer weights:\n",
      "[[ 1 -1]\n",
      " [-1  1]]\n",
      "Multiplying inputs x weights:\n",
      "[ 7 -7]\n",
      "Hidden layer biases:\n",
      "[-1 -1]\n",
      "Adding biases:\n",
      "[ 6 -8]\n",
      "Final activation values after ReLU:\n",
      "[6 0]\n",
      "Output layer weights:\n",
      "[[1 0]\n",
      " [0 1]]\n",
      "Multiplying values x weights:\n",
      "[6 0]\n",
      "Output layer biases:\n",
      "[0 0]\n",
      "Adding biases:\n",
      "[6 0]\n"
     ]
    }
   ],
   "source": [
    "### Neural network with 1 hidden layer\n",
    "import numpy as np\n",
    "\n",
    "def nn(inputs, weights, biases):\n",
    "    \"\"\"inputs is a 1 x m matrix of input values\n",
    "       weights is a list of length n, each element is an m x p matrix\n",
    "           of weights for a layer (incl. output layer)\n",
    "       biases is a p x n matrix of biases (incl. output)\n",
    "           so each column is the biases for one layer\n",
    "\n",
    "       currently only works for 1 hidden layer\n",
    "    \"\"\"\n",
    "    # Calculate values for hidden layer\n",
    "    print(\"Input values:\")\n",
    "    print(inputs)\n",
    "    print(\"Hidden layer weights:\")\n",
    "    print(weights[0])\n",
    "    print(\"Multiplying inputs x weights:\")\n",
    "    hidden_values = np.dot(inputs, weights[0]) # matrix multiplication\n",
    "\n",
    "    print(hidden_values)    \n",
    "    print(\"Hidden layer biases:\")\n",
    "    print(biases[:,0])\n",
    "    print(\"Adding biases:\")\n",
    "    hidden_values = hidden_values + biases[:,0] # add bias\n",
    "    \n",
    "    print(hidden_values)\n",
    "    hidden_values[hidden_values < 0] = 0\n",
    "    \n",
    "    print(\"Final activation values after ReLU:\")\n",
    "    print(hidden_values)\n",
    "\n",
    "    # Calculate values for output layer\n",
    "    print(\"Output layer weights:\")\n",
    "    print(weights[1])\n",
    "    print(\"Multiplying values x weights:\")\n",
    "    output_values = np.dot(hidden_values, weights[1]) # matrix multiplication\n",
    "\n",
    "    print(output_values)\n",
    "    print(\"Output layer biases:\")\n",
    "    print(biases[:,1])\n",
    "    print(\"Adding biases:\")\n",
    "    output_values = output_values + biases[:,1]\n",
    "    print(output_values) # for debugging purposes\n",
    "    \n",
    "inputs = np.array([10,3])\n",
    "hidden_weights = np.array([[1, -1],[-1, 1]])\n",
    "output_weights = np.array([[1, 0],[0, 1]])\n",
    "biases = np.array([[-1, 0], [-1, 0]])\n",
    "weights = [hidden_weights, output_weights]\n",
    "nn(inputs, weights, biases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4231518b-5f06-4160-aece-dabaad6b70a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Simpler version with for loop for deep NNs\n",
    "import numpy as np\n",
    "\n",
    "def nn(inputs, weights, biases):\n",
    "    \"\"\"inputs is a 1 x m matrix of input values\n",
    "       weights is a list of length n, each element is an m x p matrix\n",
    "           of weights for a layer (incl. output layer)\n",
    "       biases is a p x n matrix of biases (incl. output)\n",
    "           so each column is the biases for one layer\n",
    "    \"\"\"\n",
    "    # Calculate values for each layer\n",
    "    for i in range(len(weights)):\n",
    "        inputs = np.dot(inputs, weights[i]) + biases[:,i] # mat mult and bias\n",
    "        inputs[inputs < 0] = 0\n",
    "        \n",
    "    return inputs\n",
    "\n",
    "inputs = np.array([10,3])\n",
    "hidden_weights = np.array([[1, -1],[-1, 1]])\n",
    "output_weights = np.array([[1, 0],[0, 1]])\n",
    "biases = np.array([[-1, 0], [-1, 0]])\n",
    "weights = [hidden_weights, output_weights]\n",
    "nn(inputs, weights, biases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5ac6a677-31bf-4119-8c11-09b64f9c6f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Can we make a nn for \"o\" responding to \"x\" move in tic tac toe?\n",
    "inputs = np.array([0,0,0,0,0,1,0,0,0]).T # 3x3 board by rows\n",
    "weights = [np.array([[1,0,0,0,0,0,0,0,0],[1,0,0,0,0,0,0,0,0],[1,0,0,0,0,0,0,0,0],[1,0,0,0,0,0,0,0,0],[0,0,0,0,1,0,0,0,0],[1,0,0,0,0,0,0,0,0],[1,0,0,0,0,0,0,0,0],[1,0,0,0,0,0,0,0,0],[1,0,0,0,0,0,0,0,0]])]\n",
    "biases = np.array([[0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0]]).T\n",
    "# np.dot(inputs, w\n",
    "nn(inputs, weights, biases)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
